{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate a dataset for preference alignment\n",
    "\n",
    "This notebook will guide you through the process of generating a dataset for preference alignment. We'll use the `distilabel` package to generate a dataset for preference alignment.\n",
    "\n",
    "So let's dig in to some preference alignment datasets.\n",
    "\n",
    "<div style='background-color: lightblue; padding: 10px; border-radius: 5px; margin-bottom: 20px; color:black'>\n",
    "    <h2 style='margin: 0;color:blue'>Exercise: Generate a dataset for preference alignment</h2>\n",
    "    <p>Now that you've seen how to generate a dataset for preference alignment, try generating a dataset for preference alignment.</p>\n",
    "    <p><b>Difficulty Levels</b></p>\n",
    "    <p>üê¢ Generate a dataset for preference alignment</p>\n",
    "    <p>üêï Generate a dataset for preference alignment with response evolution</p>\n",
    "    <p>ü¶Å Generate a dataset for preference alignment with response evolution and model pooling</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## Install dependencies\n",
    "\n",
    "Instead of transformers, you can also install `vllm` or `hf-inference-endpoints`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install \"distilabel[hf-transformers,outlines,instructor]\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start synthesizing\n",
    "\n",
    "As we've seen in the previous notebook, we can create a distilabel pipeline for preference dataset generation. The bare minimum pipline is already provided. You can continue work on this pipeline to generate a large dataset for preference alignment. Swap out models, model providers and generation arguments to see how they affect the quality of the dataset. Experiment small, scale up later.\n",
    "\n",
    "Check out the [distilabel components gallery](https://distilabel.argilla.io/latest/components-gallery/) for information about the processing classes and how to use them. \n",
    "\n",
    "An example of loading data from the Hub instead of dictionaries is provided below.\n",
    "\n",
    "```python\n",
    "from datasets import load_dataset\n",
    "\n",
    "with Pipeline(...) as pipeline:\n",
    "    ...\n",
    "\n",
    "if __name__ == \"__main__:\n",
    "    dataset = load_dataset(\"my-dataset\", split=\"train\")\n",
    "    distiset = pipeline.run(dataset=dataset)\n",
    "```\n",
    "\n",
    "Don't forget to push your dataset to the Hub after running the pipeline!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[01/24/25 14:57:11] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'distilabel.pipeline'</span><span style=\"font-weight: bold\">]</span> üíæ Loading `_BatchManager` from cache:             <a href=\"file://c:\\Users\\xxSg\\anaconda3\\envs\\pytorch311\\Lib\\site-packages\\distilabel\\pipeline\\base.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">base.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://c:\\Users\\xxSg\\anaconda3\\envs\\pytorch311\\Lib\\site-packages\\distilabel\\pipeline\\base.py#967\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">967</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #008000; text-decoration-color: #008000\">'C:\\Users\\xxSg\\.cache\\distilabel\\pipelines\\pipeline_load_data_from_dicts_0</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">           </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #008000; text-decoration-color: #008000\">_text_generation_0_text_generation_1_group_columns_0\\3e803650c76fd2bf3ca59</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">           </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #008000; text-decoration-color: #008000\">9624bec16f2135a7401\\executions\\74a0299eb48ad0258727d61095bc0f45c7deacc8\\ba</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">           </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #008000; text-decoration-color: #008000\">tch_manager.json'</span>                                                          <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">           </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[01/24/25 14:57:11]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m \u001b[1m[\u001b[0m\u001b[32m'distilabel.pipeline'\u001b[0m\u001b[1m]\u001b[0m üíæ Loading `_BatchManager` from cache:             \u001b]8;id=309323;file://c:\\Users\\xxSg\\anaconda3\\envs\\pytorch311\\Lib\\site-packages\\distilabel\\pipeline\\base.py\u001b\\\u001b[2mbase.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=15197;file://c:\\Users\\xxSg\\anaconda3\\envs\\pytorch311\\Lib\\site-packages\\distilabel\\pipeline\\base.py#967\u001b\\\u001b[2m967\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[32m'C:\\Users\\xxSg\\.cache\\distilabel\\pipelines\\pipeline_load_data_from_dicts_0\u001b[0m \u001b[2m           \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[32m_text_generation_0_text_generation_1_group_columns_0\\3e803650c76fd2bf3ca59\u001b[0m \u001b[2m           \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[32m9624bec16f2135a7401\\executions\\74a0299eb48ad0258727d61095bc0f45c7deacc8\\ba\u001b[0m \u001b[2m           \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[32mtch_manager.json'\u001b[0m                                                          \u001b[2m           \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'distilabel.pipeline'</span><span style=\"font-weight: bold\">]</span> üíæ Loaded batch manager from cache doesn't contain <a href=\"file://c:\\Users\\xxSg\\anaconda3\\envs\\pytorch311\\Lib\\site-packages\\distilabel\\pipeline\\base.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">base.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://c:\\Users\\xxSg\\anaconda3\\envs\\pytorch311\\Lib\\site-packages\\distilabel\\pipeline\\base.py#394\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">394</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         any remaining data. Returning `Distiset` from cache data<span style=\"color: #808000; text-decoration-color: #808000\">...</span>                <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">           </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m \u001b[1m[\u001b[0m\u001b[32m'distilabel.pipeline'\u001b[0m\u001b[1m]\u001b[0m üíæ Loaded batch manager from cache doesn't contain \u001b]8;id=408652;file://c:\\Users\\xxSg\\anaconda3\\envs\\pytorch311\\Lib\\site-packages\\distilabel\\pipeline\\base.py\u001b\\\u001b[2mbase.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=158339;file://c:\\Users\\xxSg\\anaconda3\\envs\\pytorch311\\Lib\\site-packages\\distilabel\\pipeline\\base.py#394\u001b\\\u001b[2m394\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         any remaining data. Returning `Distiset` from cache data\u001b[33m...\u001b[0m                \u001b[2m           \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02cf865b50de46609a96401f431d4e8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4a869806b194c4097ba7d0354f08eb2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No files have been modified since last commit. Skipping to prevent empty commit.\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\xxSg\\anaconda3\\envs\\pytorch311\\Lib\\logging\\handlers.py\", line 1496, in emit\n",
      "    self.enqueue(self.prepare(record))\n",
      "  File \"c:\\Users\\xxSg\\anaconda3\\envs\\pytorch311\\Lib\\logging\\handlers.py\", line 1454, in enqueue\n",
      "    self.queue.put_nowait(record)\n",
      "  File \"c:\\Users\\xxSg\\anaconda3\\envs\\pytorch311\\Lib\\multiprocessing\\queues.py\", line 138, in put_nowait\n",
      "    return self.put(obj, False)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\xxSg\\anaconda3\\envs\\pytorch311\\Lib\\multiprocessing\\queues.py\", line 88, in put\n",
      "    raise ValueError(f\"Queue {self!r} is closed\")\n",
      "ValueError: Queue <multiprocessing.queues.Queue object at 0x000001764C77B9D0> is closed\n",
      "Call stack:\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"c:\\Users\\xxSg\\anaconda3\\envs\\pytorch311\\Lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"c:\\Users\\xxSg\\anaconda3\\envs\\pytorch311\\Lib\\site-packages\\traitlets\\config\\application.py\", line 992, in launch_instance\n",
      "    app.start()\n",
      "  File \"c:\\Users\\xxSg\\anaconda3\\envs\\pytorch311\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 701, in start\n",
      "    self.io_loop.start()\n",
      "  File \"c:\\Users\\xxSg\\anaconda3\\envs\\pytorch311\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 195, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"c:\\Users\\xxSg\\anaconda3\\envs\\pytorch311\\Lib\\asyncio\\windows_events.py\", line 321, in run_forever\n",
      "    super().run_forever()\n",
      "  File \"c:\\Users\\xxSg\\anaconda3\\envs\\pytorch311\\Lib\\asyncio\\base_events.py\", line 608, in run_forever\n",
      "    self._run_once()\n",
      "  File \"c:\\Users\\xxSg\\anaconda3\\envs\\pytorch311\\Lib\\site-packages\\nest_asyncio.py\", line 133, in _run_once\n",
      "    handle._run()\n",
      "  File \"c:\\Users\\xxSg\\anaconda3\\envs\\pytorch311\\Lib\\asyncio\\events.py\", line 84, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"c:\\Users\\xxSg\\anaconda3\\envs\\pytorch311\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"c:\\Users\\xxSg\\anaconda3\\envs\\pytorch311\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 523, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"c:\\Users\\xxSg\\anaconda3\\envs\\pytorch311\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 429, in dispatch_shell\n",
      "    await result\n",
      "  File \"c:\\Users\\xxSg\\anaconda3\\envs\\pytorch311\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 767, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"c:\\Users\\xxSg\\anaconda3\\envs\\pytorch311\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 429, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"c:\\Users\\xxSg\\anaconda3\\envs\\pytorch311\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"c:\\Users\\xxSg\\anaconda3\\envs\\pytorch311\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3051, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"c:\\Users\\xxSg\\anaconda3\\envs\\pytorch311\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3106, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"c:\\Users\\xxSg\\anaconda3\\envs\\pytorch311\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"c:\\Users\\xxSg\\anaconda3\\envs\\pytorch311\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3311, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"c:\\Users\\xxSg\\anaconda3\\envs\\pytorch311\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3493, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"c:\\Users\\xxSg\\anaconda3\\envs\\pytorch311\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3553, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\xxSg\\AppData\\Local\\Temp\\ipykernel_4352\\3284761107.py\", line 17, in <module>\n",
      "    distiset.push_to_hub(\"XXSg559/huggingface-smol-course-preference-tuning-dataset\")\n",
      "  File \"c:\\Users\\xxSg\\anaconda3\\envs\\pytorch311\\Lib\\site-packages\\distilabel\\distiset.py\", line 127, in push_to_hub\n",
      "    dataset.push_to_hub(\n",
      "  File \"c:\\Users\\xxSg\\anaconda3\\envs\\pytorch311\\Lib\\site-packages\\datasets\\dataset_dict.py\", line 1775, in push_to_hub\n",
      "    commit_info = api.create_commit(\n",
      "  File \"c:\\Users\\xxSg\\anaconda3\\envs\\pytorch311\\Lib\\site-packages\\huggingface_hub\\utils\\_validators.py\", line 114, in _inner_fn\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"c:\\Users\\xxSg\\anaconda3\\envs\\pytorch311\\Lib\\site-packages\\huggingface_hub\\hf_api.py\", line 1559, in _inner\n",
      "    return fn(self, *args, **kwargs)\n",
      "  File \"c:\\Users\\xxSg\\anaconda3\\envs\\pytorch311\\Lib\\site-packages\\huggingface_hub\\hf_api.py\", line 4041, in create_commit\n",
      "    logger.warning(\"No files have been modified since last commit. Skipping to prevent empty commit.\")\n",
      "Message: 'No files have been modified since last commit. Skipping to prevent empty commit.'\n",
      "Arguments: ()\n"
     ]
    }
   ],
   "source": [
    "from distilabel.llms import TransformersLLM\n",
    "from distilabel.pipeline import Pipeline\n",
    "from distilabel.steps import GroupColumns, LoadDataFromDicts\n",
    "from distilabel.steps.tasks import TextGeneration\n",
    "\n",
    "with Pipeline() as pipeline:\n",
    "    data = LoadDataFromDicts(data=[{\"instruction\": \"What is synthetic data?\"}])\n",
    "    llm_a = TransformersLLM(model=\"HuggingFaceTB/SmolLM2-1.7B-Instruct\")\n",
    "    gen_a = TextGeneration(llm=llm_a)\n",
    "    llm_b = TransformersLLM(model=\"Qwen/Qwen2.5-1.5B-Instruct\")\n",
    "    gen_b = TextGeneration(llm=llm_b)\n",
    "    group = GroupColumns(columns=[\"generation\"])\n",
    "    data >> [gen_a, gen_b] >> group\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    distiset = pipeline.run()\n",
    "    distiset.push_to_hub(\"huggingface-smol-course-preference-tuning-dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distiset = pipeline.run()\n",
    "print(distiset['default']['train'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üåØ That's a wrap\n",
    "\n",
    "You've now seen how to generate a dataset for preference alignment. You could use this to:\n",
    "\n",
    "- Generate a dataset for preference alignment.\n",
    "- Create evaluation datasets for preference alignment.\n",
    "\n",
    "Next\n",
    "\n",
    "üèãÔ∏è‚Äç‚ôÇÔ∏è Fine-tune a model with preference alignment with a synthetic dataset based on the [preference tuning chapter](../../2_preference_alignment/README.md) \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
